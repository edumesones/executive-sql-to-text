# Executive Analytics Assistant - Lending Club Dataset

Sistema multi-agente con LangGraph para anÃ¡lisis conversacional de datos financieros dirigido a directivos que necesitan insights sin escribir SQL.

## ğŸ¯ CaracterÃ­sticas Principales

- **Lenguaje Natural a SQL**: Convierte preguntas en queries SQL validadas y seguras
- **Visualizaciones Interactivas**: GrÃ¡ficos Plotly generados automÃ¡ticamente segÃºn el contexto
- **Multi-Agente con LangGraph**: OrquestaciÃ³n inteligente de especialistas (SQL, AnÃ¡lisis, VisualizaciÃ³n, Insights)
- **Memoria Conversacional**: PostgreSQL con contexto de sesiones anteriores
- **API REST + WebSocket**: Backend FastAPI con streaming de respuestas
- **Docker-Ready**: Setup completo en 2 minutos

## ğŸ“Š Dataset: Lending Club Loans

Dataset real de prÃ©stamos con +2M registros y 150+ features:
- `loan_amount`, `term`, `int_rate`, `grade`, `emp_length`
- `annual_inc`, `loan_status`, `purpose`, `dti`
- Casos de uso: anÃ¡lisis de riesgo, segmentaciÃ³n de clientes, proyecciones financieras

## ğŸ—ï¸ Arquitectura

### Diagrama de Flujo Completo

![Arquitectura del Sistema](images/arquitectura.png)

### Agentes Especializados

1. **SQL Agent**: Genera queries SQL seguras (sin DROP/DELETE/UPDATE)
2. **Analyst Agent**: Valida resultados, calcula mÃ©tricas adicionales
3. **Viz Agent**: Selecciona el tipo de grÃ¡fico Ã³ptimo (bar, line, scatter, heatmap)
4. **Insight Agent**: Genera insights de negocio y recomendaciones

## ğŸš€ Quick Start

### 1. Prerequisitos

```bash
# Windows
python --version  # 3.10+
docker --version
```

### 2. Setup

```bash
# Clonar y entrar al proyecto
cd D:\executive_sql_to_text

# Crear entorno virtual
python -m venv venv
venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Variables de entorno
copy .env.example .env
# Editar .env con tus API keys
```

### 3. Levantar servicios Docker

```bash
docker-compose up -d
```

Servicios disponibles:
- PostgreSQL: `localhost:5432`
- pgAdmin: `http://localhost:5050` (admin@example.com / admin)
- API: `http://localhost:8000` (despuÃ©s de correr la app)

### 4. Cargar datos

```bash
# Descargar dataset (primeras 100k filas para demo)
python scripts/download_data.py

# Cargar en PostgreSQL
python scripts/seed_database.py
```

### 5. Ejecutar aplicaciÃ³n

```bash
# Backend API
uvicorn src.api.main:app --reload --port 8000

# Frontend Streamlit (nueva terminal)
streamlit run frontend/streamlit_app.py
```

Acceder a: `http://localhost:8501`

## ğŸ“ Estructura del Proyecto

```
executive_sql_to_text/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/              # Agentes especializados
â”‚   â”‚   â”œâ”€â”€ base_agent.py
â”‚   â”‚   â”œâ”€â”€ sql_agent.py
â”‚   â”‚   â”œâ”€â”€ analyst_agent.py
â”‚   â”‚   â”œâ”€â”€ viz_agent.py
â”‚   â”‚   â””â”€â”€ insight_agent.py
â”‚   â”œâ”€â”€ graph/               # LangGraph workflow
â”‚   â”‚   â”œâ”€â”€ state.py
â”‚   â”‚   â”œâ”€â”€ nodes.py
â”‚   â”‚   â””â”€â”€ workflow.py
â”‚   â”œâ”€â”€ tools/               # Herramientas reutilizables
â”‚   â”‚   â”œâ”€â”€ sql_executor.py
â”‚   â”‚   â”œâ”€â”€ chart_generator.py
â”‚   â”‚   â””â”€â”€ metric_calculator.py
â”‚   â”œâ”€â”€ database/            # Modelos y persistencia
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”œâ”€â”€ connection.py
â”‚   â”‚   â””â”€â”€ query_cache.py
â”‚   â””â”€â”€ api/                 # FastAPI backend
â”‚       â”œâ”€â”€ main.py
â”‚       â”œâ”€â”€ routes.py
â”‚       â””â”€â”€ websocket.py
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ streamlit_app.py     # UI para directivos
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # CSVs descargados
â”‚   â””â”€â”€ processed/           # Datos limpios
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_data.py     # Descarga dataset
â”‚   â””â”€â”€ seed_database.py     # Carga en PostgreSQL
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ postgres/
â”‚       â””â”€â”€ init.sql         # Schema inicial
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ agents.yaml          # ConfiguraciÃ³n de agentes
â”‚   â””â”€â”€ database.yaml        # ConfiguraciÃ³n de DB
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â””â”€â”€ integration/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## ğŸ’¬ Ejemplos de Preguntas

### AnÃ¡lisis de Riesgo
```
"Â¿CuÃ¡l es la tasa de default por grade de prÃ©stamo?"
"MuÃ©strame la distribuciÃ³n de loan_status"
"Â¿QuÃ© factores predicen mejor el default?"
```

### SegmentaciÃ³n
```
"Segmenta clientes por annual_income y loan_amount"
"Â¿CuÃ¡les son los perfiles de mayor riesgo?"
"AnÃ¡lisis de prÃ©stamos por purpose (debt_consolidation, credit_card, etc)"
```

### Proyecciones Financieras
```
"Proyecta ingresos por intereses del prÃ³ximo trimestre"
"Â¿QuÃ© grade tiene mejor ROI ajustado por riesgo?"
"AnÃ¡lisis de rentabilidad por term (36 vs 60 meses)"
```

### Operaciones
```
"Â¿CuÃ¡ntos prÃ©stamos estÃ¡n en mora actualmente?"
"Tiempo promedio hasta el primer pago"
"DistribuciÃ³n geogrÃ¡fica de prÃ©stamos (por state)"
```

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno (.env)

```bash
# LLM API Keys
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...

# Database
DATABASE_URL=postgresql://analyst:password@localhost:5432/lending_club
DB_PASSWORD=password

# API
API_HOST=0.0.0.0
API_PORT=8000
CORS_ORIGINS=http://localhost:8501,http://localhost:3000

# LangSmith (opcional para tracing)
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=ls__...
LANGCHAIN_PROJECT=executive-analytics
```

### ConfiguraciÃ³n de Agentes (config/agents.yaml)

```yaml
sql_agent:
  model: gpt-4o-mini
  temperature: 0.0
  max_retries: 3
  allowed_operations: [SELECT]
  
viz_agent:
  model: gpt-4o-mini
  temperature: 0.3
  chart_library: plotly
  default_theme: plotly_white
```

## ğŸ§ª Testing

```bash
# Tests unitarios
pytest tests/unit -v

# Tests de integraciÃ³n (requiere Docker corriendo)
pytest tests/integration -v

# Coverage
pytest --cov=src tests/
```

## ğŸ“Š Schema de Base de Datos

### Tabla Principal: `loans`

```sql
CREATE TABLE loans (
    id SERIAL PRIMARY KEY,
    loan_amnt DECIMAL(10, 2),
    term VARCHAR(20),
    int_rate DECIMAL(5, 2),
    grade VARCHAR(1),
    sub_grade VARCHAR(2),
    emp_length VARCHAR(20),
    home_ownership VARCHAR(20),
    annual_inc DECIMAL(12, 2),
    verification_status VARCHAR(50),
    loan_status VARCHAR(50),
    purpose VARCHAR(50),
    dti DECIMAL(5, 2),
    delinq_2yrs INTEGER,
    earliest_cr_line DATE,
    open_acc INTEGER,
    pub_rec INTEGER,
    revol_bal DECIMAL(12, 2),
    revol_util DECIMAL(5, 2),
    total_acc INTEGER,
    addr_state VARCHAR(2),
    issue_d DATE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_loan_status ON loans(loan_status);
CREATE INDEX idx_grade ON loans(grade);
CREATE INDEX idx_issue_date ON loans(issue_d);
```

### Tabla de Conversaciones

```sql
CREATE TABLE conversations (
    id SERIAL PRIMARY KEY,
    session_id UUID NOT NULL,
    user_query TEXT,
    sql_query TEXT,
    results JSONB,
    chart_config JSONB,
    insights TEXT[],
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

## ğŸ¨ Frontend Features

- **Chat Interface**: ConversaciÃ³n natural con el sistema
- **SQL Transparency**: Ver query generada (expandible)
- **GrÃ¡ficos Interactivos**: Zoom, pan, hover tooltips
- **ExportaciÃ³n**: Descargar datos en CSV/Excel
- **Historial**: Acceso a consultas anteriores
- **MÃ©tricas en Tiempo Real**: KPIs destacados

## ğŸ” Seguridad

- âœ… SQL Injection Protection: Queries parametrizadas con SQLAlchemy
- âœ… Solo operaciones SELECT permitidas
- âœ… Rate limiting en API (100 req/min por IP)
- âœ… ValidaciÃ³n de schemas con Pydantic
- âœ… CORS configurado para dominios especÃ­ficos

## ğŸš¢ Deployment

### Docker Production

```bash
docker-compose -f docker-compose.prod.yml up -d
```

### Variables para ProducciÃ³n

```bash
# .env.prod
DATABASE_URL=postgresql://user:pass@prod-db:5432/lending_club
OPENAI_API_KEY=sk-...
API_HOST=0.0.0.0
API_PORT=8000
ENVIRONMENT=production
LOG_LEVEL=INFO
```

## ğŸ“ˆ Roadmap

- [ ] **Fase 1** (Actual): Sistema base funcional con 4 agentes
- [ ] **Fase 2**: AÃ±adir agente de ML para predicciones (default risk)
- [ ] **Fase 3**: Benchmarking de modelos (GPT-4 vs Claude vs Llama)
- [ ] **Fase 4**: Multi-dataset support (aÃ±adir otros CSV)
- [ ] **Fase 5**: AutenticaciÃ³n y multi-tenancy

## ğŸ¤ ContribuciÃ³n

Este es un proyecto de portfolio, pero sugerencias son bienvenidas:

1. Fork del repo
2. Crea branch (`git checkout -b feature/amazing`)
3. Commit (`git commit -m 'Add amazing feature'`)
4. Push (`git push origin feature/amazing`)
5. Abre Pull Request

## ğŸ“„ Licencia

MIT License - ver `LICENSE` file

## ğŸ‘¤ Autor

**Glemes - GLEMES FFT (Focus Flow Tech)**
- Data Scientist & Python Expert
- EspecializaciÃ³n: ML/AI para banca y retail
- LinkedIn: [tu-linkedin]
- Portfolio: [tu-portfolio]

---

**â­ Si te resulta Ãºtil, dale una estrella al repo!**
